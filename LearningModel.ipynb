{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in numpy  array data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_data = pickle.load(open('cat_data.pickle','rb'))\n",
    "dog_data = pickle.load(open('dog_data.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed the data more to fit the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Used this process once to binary classify dogs and cats\n",
    "# cat = np.ones((len(cat_data), 1))\n",
    "# cat_data = np.hstack((cat, cat_data))\n",
    "#dog = np.zeros((len(dog_data), 1))\n",
    "#dog_data = np.hstack((dog, dog_data))\n",
    "# pickle.dump(cat_data, open(\"cat_data.pickle\",\"wb\"))\n",
    "#pickle.dump(dog_data, open(\"dog_data.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_preprocessing(cat_data, dog_data):\n",
    "    data = np.concatenate((cat_data, dog_data), axis = 0)\n",
    "    np.random.shuffle(data)\n",
    "    trans_data = data.T\n",
    "    y = trans_data[0]\n",
    "    X = np.delete(trans_data, 0, 0).T\n",
    "    return (X, y)\n",
    "\n",
    "X_train, y_train = train_preprocessing(cat_data, dog_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the keras libraries for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import losses\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the train data palatable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure the y_train is categorically one_hot\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "#make sure the X_train data is correct dimension\n",
    "X_train = np.reshape(X_train, (25000,128,128,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sequential model chose\n",
    "model = Sequential()\n",
    "#normalized data and used convolution\n",
    "#The inspiration for this model comes from the cifar10 dataset\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,\n",
    "                 (12,12),\n",
    "                 padding='same',\n",
    "                 strides=1,\n",
    "                 input_shape=(X_train.shape[1:])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(optimizer= 'rmsprop',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 20, shuffle=True, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model's weight data and model into a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# model.save('cat_dog_model.h5')\n",
    "model_json = model.to_json()\n",
    "with open(\"model_cat_dog.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model_cat_dog.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
